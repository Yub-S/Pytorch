{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IT6fDWVXyiHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba858f80-6f18-44b7-be4d-6a90fc6019d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([78330.7500])\n",
            "tensor([78330.7500])\n",
            "tensor([[7.8331e+04, 4.5168e-41, 3.3558e-18],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
            "tensor([[[1.9784e-40, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [1.4013e-45, 0.0000e+00,        nan,        nan],\n",
            "         [2.0179e-43, 0.0000e+00, 2.7045e-43, 0.0000e+00]],\n",
            "\n",
            "        [[3.3481e-18, 0.0000e+00, 7.8330e+04, 4.5168e-41],\n",
            "         [1.4013e-45, 0.0000e+00,        nan,        nan],\n",
            "         [2.6905e-43, 0.0000e+00, 6.7262e-44, 0.0000e+00]]])\n",
            "tensor([[0.9603, 0.4692, 0.2600],\n",
            "        [0.0297, 0.8320, 0.6436],\n",
            "        [0.9265, 0.2644, 0.8437],\n",
            "        [0.2285, 0.0901, 0.9455],\n",
            "        [0.3112, 0.8148, 0.4276]])\n",
            "tensor([[[0.2669, 0.1366, 0.1740],\n",
            "         [0.1841, 0.2330, 0.8335],\n",
            "         [0.3483, 0.8932, 0.1020]],\n",
            "\n",
            "        [[0.3552, 0.5171, 0.7181],\n",
            "         [0.9393, 0.5479, 0.9233],\n",
            "         [0.0200, 0.1657, 0.3726]],\n",
            "\n",
            "        [[0.0133, 0.4277, 0.5700],\n",
            "         [0.8493, 0.6973, 0.7234],\n",
            "         [0.3220, 0.5212, 0.2050]],\n",
            "\n",
            "        [[0.3781, 0.2305, 0.8329],\n",
            "         [0.2261, 0.8124, 0.0337],\n",
            "         [0.3300, 0.0573, 0.8196]],\n",
            "\n",
            "        [[0.8756, 0.8896, 0.4533],\n",
            "         [0.9784, 0.4289, 0.3141],\n",
            "         [0.5249, 0.8652, 0.3617]]])\n",
            "tensor([0.0058])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n"
          ]
        }
      ],
      "source": [
        "#tensor\n",
        "import torch\n",
        "\n",
        "# torch.empty(shape) to allocate memeory for torch tensor with given shape, but the values in it are uninitialized\n",
        "x = torch.empty (1)\n",
        "print(x)\n",
        "y = torch.empty(2)\n",
        "print(x)\n",
        "z = torch.empty(2,3)\n",
        "print(z)\n",
        "a = torch.empty(2,3,4)\n",
        "print(a)\n",
        "\n",
        "# torch.rand (shape) initialize random numbers from 0 to 1 --- torch.randn(shape) for random numbers from 1 to inf.\n",
        "p = torch.rand([5,3])\n",
        "print(p)\n",
        "q = torch.rand([5,3,3])\n",
        "print(q)\n",
        "r = torch.randn([1])\n",
        "print(r)\n",
        "\n",
        "# torch.zeros(shape) and torch.ones (shape)\n",
        "d = torch.zeros([2,3])\n",
        "e = torch.ones([1,2,3])\n",
        "print(d)\n",
        "print(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape or size of the tensors tensor.shape or tensor.size()\n",
        "print(\"shape :\",x.shape)\n",
        "print(\"size :\",y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShHvBGOey5SI",
        "outputId": "c1a75f2f-c6c9-4c27-c269-aa3037477ce0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape : torch.Size([1])\n",
            "size : torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the datatypes\n",
        "print(\"datatype :\",x.dtype)\n",
        "\n",
        "# default float32, we can specify by torch.float64\n",
        "v = torch.rand([2,3],dtype=torch.float16)\n",
        "print(\"datatype :\",v.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uT9Div71snm",
        "outputId": "b36985d5-4e83-4b17-c4da-2f991f2585c7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datatype : torch.float32\n",
            "datatype : torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# constructing the tensors\n",
        "x = torch.tensor([3,4,5])\n",
        "print(x,x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fow-_vh95wKz",
        "outputId": "f0b7de09-ebb5-443d-f40b-fe23704fb057"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 4, 5]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# requires gradients ...torch keeps tract of the variable for computing gradinents by default\n",
        "# specified false, we keep requires grad = True for all variables we need to optimize\n",
        "x = torch.rand([3,4,2],requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpS9Bs0E6a_b",
        "outputId": "2d55fec9-c2ea-4766-95d0-59bb48c82030"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.3152, 0.2445],\n",
            "         [0.0659, 0.2334],\n",
            "         [0.9783, 0.5848],\n",
            "         [0.0982, 0.3640]],\n",
            "\n",
            "        [[0.1387, 0.3511],\n",
            "         [0.4334, 0.5036],\n",
            "         [0.2668, 0.8802],\n",
            "         [0.1001, 0.1880]],\n",
            "\n",
            "        [[0.8020, 0.5301],\n",
            "         [0.7206, 0.7784],\n",
            "         [0.8472, 0.4149],\n",
            "         [0.2028, 0.8670]]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple operations on tensor addition, subs,mul,div\n",
        "\n",
        "x = torch.ones([2,2])\n",
        "y = torch.ones([2,2])\n",
        "\n",
        "z = x+y\n",
        "p = torch.add(x,y)\n",
        "r = y.add(x) # y.add_(x) is inplace=true addition\n",
        "print(x,y,z,p,r)\n",
        "\n",
        "a = x-y\n",
        "b = x * y\n",
        "c = x/y\n",
        "print(a,b,c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcnrACgh7Ekr",
        "outputId": "3d5a7c32-d7c7-47dc-ef91-5ff0a884977c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]]) tensor([[1., 1.],\n",
            "        [1., 1.]]) tensor([[2., 2.],\n",
            "        [2., 2.]]) tensor([[2., 2.],\n",
            "        [2., 2.]]) tensor([[2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.]]) tensor([[1., 1.],\n",
            "        [1., 1.]]) tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# slicing\n",
        "print(x[:,1])\n",
        "\n",
        "# get the float value if there is single item in our tensor with item()\n",
        "print(x[1,1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSIEAMU78XaJ",
        "outputId": "b81c2c6d-4672-4142-eb88-34e44808d987"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1.])\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping the shape of tensors using view()\n",
        "m = torch.rand([4,4])\n",
        "n = m.view(16)\n",
        "o = m.view(-1,8) # -1 automatically identifies the correct shape, as we need 8 cols so the prior value would be 2\n",
        "\n",
        "print(m.shape,n.shape,n.shape)\n",
        "print(m,n,o)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN3uxlpX89G5",
        "outputId": "3b7800ca-be6d-4afd-8408-05538f2379bc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([16])\n",
            "tensor([[0.0994, 0.9870, 0.4609, 0.1777],\n",
            "        [0.3087, 0.9477, 0.8425, 0.8061],\n",
            "        [0.8372, 0.2389, 0.0223, 0.6671],\n",
            "        [0.3830, 0.3558, 0.8153, 0.6025]]) tensor([0.0994, 0.9870, 0.4609, 0.1777, 0.3087, 0.9477, 0.8425, 0.8061, 0.8372,\n",
            "        0.2389, 0.0223, 0.6671, 0.3830, 0.3558, 0.8153, 0.6025]) tensor([[0.0994, 0.9870, 0.4609, 0.1777, 0.3087, 0.9477, 0.8425, 0.8061],\n",
            "        [0.8372, 0.2389, 0.0223, 0.6671, 0.3830, 0.3558, 0.8153, 0.6025]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conversion from numpy to tensor and vice versa\n",
        "import numpy as np\n",
        "x = np.random.rand(2,3)\n",
        "y = torch.from_numpy(x)\n",
        "z = torch.tensor(x) # either from_numpy or with tensor\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "\n",
        "# when using cpu, both numpy array and pytorch tensor (created from numpy ) occupy same mem location, so if we change any of them, the other will also change\n",
        "# here x is a numpy array, y is a tensor created using from numpy, and z is a tensor created using tensor, so x and y will remain same but z remains unchanged.\n",
        "# .tensor() creates a new mem location and new array.\n",
        "y.add_(5)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyscXBxl9lOe",
        "outputId": "fc547a21-2f44-46e0-9c64-4dd291ab1f65"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2419543  0.39194978 0.54398543]\n",
            " [0.70746641 0.17014093 0.15646848]]\n",
            "tensor([[0.2420, 0.3919, 0.5440],\n",
            "        [0.7075, 0.1701, 0.1565]], dtype=torch.float64)\n",
            "tensor([[0.2420, 0.3919, 0.5440],\n",
            "        [0.7075, 0.1701, 0.1565]], dtype=torch.float64)\n",
            "[[5.2419543  5.39194978 5.54398543]\n",
            " [5.70746641 5.17014093 5.15646848]]\n",
            "tensor([[5.2420, 5.3919, 5.5440],\n",
            "        [5.7075, 5.1701, 5.1565]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# by default all the tensors are created in cpu, to move to gpu or create them on gpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # can specify cuda:0 or cuda:1 or likewise if we have multiple gpus\n",
        "\n",
        "x = torch.rand([2,3]).to(device) # move to the gpu\n",
        "y = torch.rand([2,3],device=device) # directly create in gpu --- this one is efficient\n"
      ],
      "metadata": {
        "id": "kkG9DcdRFpUp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autograd"
      ],
      "metadata": {
        "id": "E3xOH-2TK-8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# autograd requires the require_grad argument in tensor creation to be true so that pytorch can track it\n",
        "f = torch.rand([2,3],requires_grad=True)\n",
        "\n",
        "g = f + 2\n",
        "\n",
        "print(f)\n",
        "print(g)\n",
        "print(g.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2kScAVeI6F1",
        "outputId": "fcb2bd0d-0939-4f8d-df9b-7ae025959b9a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7175, 0.0520, 0.4589],\n",
            "        [0.5684, 0.6822, 0.3791]], requires_grad=True)\n",
            "tensor([[2.7175, 2.0520, 2.4589],\n",
            "        [2.5684, 2.6822, 2.3791]], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7de82d280400>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = g * g *3\n",
        "print(h)\n",
        "h = h.mean()\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bloyuYOcLXdo",
        "outputId": "a97ea84e-808c-46bf-b88d-4712af61c9a8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[22.1541, 12.6322, 18.1390],\n",
            "        [19.7906, 21.5827, 16.9804]], grad_fn=<MulBackward0>)\n",
            "tensor(18.5465, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can call h.backward() to compute gradients automatically during backpropagation, tensor with requires_grad = True will have a grad attribute\n",
        "# where the gradients will be stored.\n",
        "\n",
        "print(f.grad) # none as we havent called the backward fn\n",
        "h.backward() # computes dh/df\n",
        "print(f.grad)\n",
        "\n",
        "# .backward() actually accumulates the gradients so we must later on do something like optimizer.zero_grad() or tensor like w.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx7UuIciMBDL",
        "outputId": "29f2de46-e3a9-4d0e-af3a-bfc7113ae4aa"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([[2.7175, 2.0520, 2.4589],\n",
            "        [2.5684, 2.6822, 2.3791]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can stop the tracking by using requires_grad = false or with torch.no_grad()\n",
        "# we often need to stop tracking of the tensor during updates on weights during training or after training during evaluation.\n",
        "\n",
        "i = torch.randn([2,3], requires_grad=True)\n",
        "j = (i*i).sum()\n",
        "print(i)\n",
        "print(j.grad_fn)\n",
        "\n",
        "# . detach gets the same copy of the tensor but with no grad tracking\n",
        "k = i.detach() # we dont want to track k\n",
        "print(k.requires_grad)\n",
        "\n",
        "# or we can also use with torch.no_grad()\n",
        "with torch.no_grad():\n",
        "  l = i*i\n",
        "  print(l.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUyhm2SOMnYs",
        "outputId": "bdffa4db-4286-44e0-bc8b-de607bccfe3b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9647,  0.5208,  0.0267],\n",
            "        [ 0.8714,  0.5180, -0.3480]], requires_grad=True)\n",
            "<SumBackward0 object at 0x7de82dea78e0>\n",
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZctoOj4rOxh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### simple linear regression with autograd\n",
        "y = wx + b, b =0 and w = 2 , y = 2x is our true function"
      ],
      "metadata": {
        "id": "gYqTnmhRV_hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([1,2,3,4,5,6,7,8,9],dtype=torch.float32)\n",
        "y = torch.tensor([2,4,6,8,10,12,14,16,18],dtype = torch.float32)\n",
        "\n",
        "w = torch.tensor([0],dtype = torch.float32, requires_grad = True)\n",
        "\n",
        "# defining forward function\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "# calculating loss : MSE\n",
        "def loss (y_pred,y):\n",
        "  return ((y-y_pred)**2).mean()\n",
        "\n",
        "x_test = 10.0\n",
        "print(\"before training y = \", forward(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHv-4qytWDxo",
        "outputId": "4ee65ab2-9317-4875-fa5f-2a7770faf6fe"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before training y =  tensor([0.], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # forward pass\n",
        "  y_pred = forward(x)\n",
        "  # calculate loss\n",
        "  l = loss(y,y_pred)\n",
        "  # backward pass i.e gradient calc\n",
        "  l.backward()\n",
        "  # optimize the model i.e update weights\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epoch%9==0:\n",
        "    print(f\"after epoch {epoch} w : {w.item():.3f} loss : {l.item():.3f}\")\n",
        "\n",
        "print(\"after training y = \", forward(x_test).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXJp7NvicKLs",
        "outputId": "8ace1359-0611-4121-c415-6341f6a98c4d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after epoch 0 w : 2.000 loss : 0.000\n",
            "after epoch 9 w : 2.000 loss : 0.000\n",
            "after epoch 18 w : 2.000 loss : 0.000\n",
            "after epoch 27 w : 2.000 loss : 0.000\n",
            "after epoch 36 w : 2.000 loss : 0.000\n",
            "after epoch 45 w : 2.000 loss : 0.000\n",
            "after epoch 54 w : 2.000 loss : 0.000\n",
            "after epoch 63 w : 2.000 loss : 0.000\n",
            "after epoch 72 w : 2.000 loss : 0.000\n",
            "after epoch 81 w : 2.000 loss : 0.000\n",
            "after epoch 90 w : 2.000 loss : 0.000\n",
            "after epoch 99 w : 2.000 loss : 0.000\n",
            "after training y =  20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### pytorch ofcourse has defined loss and optimizers. lets implement our simple linear regression in pytorch style. The general pipeline is often definiing the model its inputs and outputs and forward pass and layers, constructing loss and optimizers, and training i.e forward pass, backward pass and updates."
      ],
      "metadata": {
        "id": "FNzT0kG80KO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# defining input and output data\n",
        "x = torch.tensor([1,2,3,4,5,6,7,8,9],dtype=torch.float32)\n",
        "y = torch.tensor([2,4,6,8,10,12,14,16,18],dtype=torch.float32)\n",
        "\n",
        "print(x.shape,y.shape)\n",
        "\n",
        "x = x.view(-1,1)\n",
        "y = y.view(-1,1) # n samples 1 feature\n",
        "\n",
        "print(x.shape,y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHi4tJYwoJ7M",
        "outputId": "9bb76da4-cb7c-4bde-9ac4-630e52cb2968"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9]) torch.Size([9])\n",
            "torch.Size([9, 1]) torch.Size([9, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining model\n",
        "import torch.nn as nn\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "\n",
        "  def __init__(self,input_dim,output_dim):\n",
        "    super(LinearRegression,self).__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_dim,output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return (self.lin(x))\n",
        "\n",
        "n_samples,n_features = x.shape\n",
        "model = LinearRegression(input_dim = n_features, output_dim = n_features)  # 1,1\n",
        "\n",
        "# prediction before training\n",
        "x_test = torch.tensor([10.0],dtype=torch.float32)\n",
        "print(f\"before training y_pred = {model(x_test).item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsB66Wqaz9HD",
        "outputId": "997713c6-8781-43a7-a0fb-2d87d346c5a1"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before training y_pred = -2.547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining loss and optimizer\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
        "\n",
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # forward pass\n",
        "  y_pred = model(x)\n",
        "  # loss\n",
        "  l = loss(y,y_pred)\n",
        "  # backward pass\n",
        "  l.backward()\n",
        "\n",
        "  # optimize\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 9 ==0:\n",
        "    w,b = model.parameters() # unpacking the parameters\n",
        "    print(f\"epoch {epoch} loss = {l.item():.3f} w= {w[0][0].item():.3f}\")\n",
        "\n",
        "print(f\"after training y_pred = {model(x_test).item():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqGrubFj3nTw",
        "outputId": "920f4156-cc7d-44a0-d79b-1fd63c7f7636"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 loss = 153.309 w= 1.042\n",
            "epoch 9 loss = 0.333 w= 1.801\n",
            "epoch 18 loss = 0.309 w= 1.808\n",
            "epoch 27 loss = 0.287 w= 1.815\n",
            "epoch 36 loss = 0.266 w= 1.822\n",
            "epoch 45 loss = 0.247 w= 1.828\n",
            "epoch 54 loss = 0.230 w= 1.835\n",
            "epoch 63 loss = 0.213 w= 1.841\n",
            "epoch 72 loss = 0.198 w= 1.846\n",
            "epoch 81 loss = 0.184 w= 1.852\n",
            "epoch 90 loss = 0.171 w= 1.857\n",
            "epoch 99 loss = 0.159 w= 1.863\n",
            "after training y_pred = 19.491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classic example of nn as universal approximator\n",
        "\n",
        "import torch\n",
        "\n",
        "# Defining the range for x1 and x2\n",
        "numbers = list(range(1, 10)) # [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "X_data = [] # Features (x1, x2)\n",
        "y_data = [] # Labels (x1 + x2)\n",
        "\n",
        "# Generate data for all combinations\n",
        "for x1 in numbers:\n",
        "    for x2 in numbers:\n",
        "        X_data.append([float(x1), float(x2)]) # Ensure floats for potential torch.float32\n",
        "        y_data.append(float(x1 + x2))\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "# Features: Shape (81, 2)\n",
        "X = torch.tensor(X_data, dtype=torch.float32)\n",
        "\n",
        "# Labels: Shape (81, 1) - ensure it's a column vector for consistent loss calculation\n",
        "y = torch.tensor(y_data, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "print(\"Shape of X (features):\", X.shape)\n",
        "print(\"Shape of y (labels):\", y.shape)\n",
        "\n",
        "x_test = torch.tensor([12,13],dtype=torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMWjJyam6H4A",
        "outputId": "949582ea-4784-4b4d-da2a-61e7913d1d3d"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X (features): torch.Size([81, 2])\n",
            "Shape of y (labels): torch.Size([81, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = LinearRegression(input_dim=2,output_dim=1)\n",
        "\n",
        "# defining loss and optimizer\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model2.parameters(),lr = learning_rate)\n",
        "\n",
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # forward pass\n",
        "  y_pred = model2(X)\n",
        "  # loss\n",
        "  l = loss(y,y_pred)\n",
        "  # backward pass\n",
        "  l.backward()\n",
        "\n",
        "  # optimize\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 9 ==0:\n",
        "    w,b = model2.parameters() # unpacking the parameters\n",
        "    print(f\"epoch {epoch} loss = {l.item():.3f} w= {w[0][0].item():.3f}\")\n",
        "\n",
        "print(f\"after training y_pred = {model2(x_test).item():.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPN6ZX7w-QDQ",
        "outputId": "40fc646b-b7bb-4f95-d558-1cc543b02442"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 loss = 43.101 w= 1.316\n",
            "epoch 9 loss = 0.068 w= 1.064\n",
            "epoch 18 loss = 0.005 w= 1.019\n",
            "epoch 27 loss = 0.000 w= 1.006\n",
            "epoch 36 loss = 0.000 w= 1.003\n",
            "epoch 45 loss = 0.000 w= 1.002\n",
            "epoch 54 loss = 0.000 w= 1.002\n",
            "epoch 63 loss = 0.000 w= 1.002\n",
            "epoch 72 loss = 0.000 w= 1.002\n",
            "epoch 81 loss = 0.000 w= 1.002\n",
            "epoch 90 loss = 0.000 w= 1.002\n",
            "epoch 99 loss = 0.000 w= 1.002\n",
            "after training y_pred = 25.021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2o1uSxcbBBCY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}